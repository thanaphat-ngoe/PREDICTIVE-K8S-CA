{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1771562023923,
     "user": {
      "displayName": "Thanaphat Ngoennet",
      "userId": "16019981373821365348"
     },
     "user_tz": -420
    },
    "id": "IsOQG8J1UxcM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1771562023926,
     "user": {
      "displayName": "Thanaphat Ngoennet",
      "userId": "16019981373821365348"
     },
     "user_tz": -420
    },
    "id": "QQXizEguxWiS"
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1771562027250,
     "user": {
      "displayName": "Thanaphat Ngoennet",
      "userId": "16019981373821365348"
     },
     "user_tz": -420
    },
    "id": "PaJWjBabaX0Q",
    "outputId": "fc818d1e-a1d1-4f4a-f55f-e358edefc625"
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 30\n",
    "FORECAST_HORIZON = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROJECT_PATH + '/LSTM_Ready_Dataset_Old.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# SETUP & DATA LOADING\n",
    "# =====================================================================\n",
    "\n",
    "cluster_cpu_req = pd.DataFrame(\n",
    "    {'cluster_cpu_req': df['node_cpu_req_aj-aung-k8s-worker1'] + df['node_cpu_req_aj-aung-k8s-worker2']}\n",
    ")\n",
    "\n",
    "cluster_cpu_cap = pd.DataFrame(\n",
    "    {'cluster_cpu_cap': df['node_cpu_cap_aj-aung-k8s-worker1'] + df['node_cpu_cap_aj-aung-k8s-worker2']}\n",
    ")\n",
    "\n",
    "cluster_mem_req = pd.DataFrame(\n",
    "    {'cluster_mem_req': df['node_mem_req_aj-aung-k8s-worker1'] + df['node_mem_req_aj-aung-k8s-worker2']}\n",
    ")\n",
    "\n",
    "cluster_mem_cap = pd.DataFrame(\n",
    "    {'cluster_mem_cap': df['node_mem_cap_aj-aung-k8s-worker1'] + df['node_mem_cap_aj-aung-k8s-worker2']}\n",
    ")\n",
    "\n",
    "features = pd.concat([cluster_cpu_req, cluster_cpu_cap, cluster_mem_req, cluster_mem_cap, df['cluster_pods_pending']], axis = 1)\n",
    "\n",
    "target = cluster_cpu_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.info()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# CHRONOLOGICAL SPLIT (70/15/15)\n",
    "# =====================================================================\n",
    "\n",
    "n = len(features)\n",
    "\n",
    "train_idx = int(n * 0.7)\n",
    "val_idx   = int(n * 0.85)\n",
    "\n",
    "# Split features (for X)\n",
    "X_train_raw = features[:train_idx]\n",
    "X_val_raw   = features[train_idx:val_idx]\n",
    "X_test_raw  = features[val_idx:]\n",
    "\n",
    "# Split target (for y)\n",
    "y_train_raw = target[:train_idx]\n",
    "y_val_raw   = target[train_idx:val_idx]\n",
    "y_test_raw  = target[val_idx:]\n",
    "\n",
    "X_train_raw.shape, X_val_raw.shape, X_test_raw.shape, y_train_raw.shape, y_val_raw.shape, y_test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# DUAL SCALING (CRITICAL STEP)\n",
    "# =====================================================================\n",
    "\n",
    "scaler_inputs  = MinMaxScaler(feature_range = (0, 1))\n",
    "X_train_scaled = scaler_inputs.fit_transform(X_train_raw)\n",
    "X_val_scaled   = scaler_inputs.transform(X_val_raw)\n",
    "X_test_scaled  = scaler_inputs.transform(X_test_raw)\n",
    "\n",
    "scaler_target  = MinMaxScaler(feature_range = (0, 1))\n",
    "y_train_scaled = scaler_target.fit_transform(y_train_raw)\n",
    "y_val_scaled   = scaler_target.transform(y_val_raw)\n",
    "y_test_scaled  = scaler_target.transform(y_test_raw)\n",
    "\n",
    "joblib.dump(scaler_inputs, 'Multi-Var_Scaler_Inputs.pkl')\n",
    "joblib.dump(scaler_target, 'Multi-Var_Scaler_Target.pkl')\n",
    "print(\"Success: 'Multi-Var_Scaler_Inputs.pkl' & 'Multi-Var_Scaler_Target.pkl' saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# SLIDING WINDOW (MULTIVARIATE)\n",
    "# =====================================================================\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size):\n",
    "\tdata   = []\n",
    "\tlabels = []\n",
    "\n",
    "\tstart_index = start_index + history_size\n",
    "\tif end_index is None:\n",
    "\t\tend_index = len(dataset) - target_size\n",
    "\n",
    "\tfor i in range(start_index, end_index):\n",
    "\t\tindices = range(i - history_size, i)\n",
    "\t\tdata.append(dataset[indices])\n",
    "\t\tlabels.append(target[i + target_size])\n",
    "\n",
    "\treturn np.array(data), np.array(labels)\n",
    "\n",
    "X_train, y_train = multivariate_data(X_train_scaled, y_train_scaled, 0, None, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "X_val  , y_val   = multivariate_data(X_val_scaled  , y_val_scaled  , 0, None, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "X_test , y_test  = multivariate_data(X_test_scaled , y_test_scaled , 0, None, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Target Shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1], X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units = 256, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mae', optimizer = 'adam')\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 32, validation_data = (X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 10))\n",
    "plt.plot(history.history['loss'], label = 'Train Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# EVALUATION & PLOTTING\n",
    "# =====================================================================\n",
    "\n",
    "y_scaled_predicted = model.predict(X_test)\n",
    "\n",
    "y_predicted_converted_back = scaler_target.inverse_transform(y_scaled_predicted)\n",
    "y_actuals                  = scaler_target.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_actuals, y_predicted_converted_back))\n",
    "mae = mean_absolute_error(y_actuals, y_predicted_converted_back)\n",
    "r2 = r2_score(y_actuals, y_predicted_converted_back)\n",
    "mape = mean_absolute_percentage_error(y_actuals, y_predicted_converted_back) * 100\n",
    "\n",
    "print(\"\\n--- OFFICIAL AUTOSCALER PERFORMANCE ---\")\n",
    "print(f\"Test RMSE: {rmse:.2f} vCores\")\n",
    "print(f\"Test MAE:  {mae:.2f} vCores\")\n",
    "print(f\"On average, the model's 5-minute forecast is off by {mae:.2f} vCores.\")\n",
    "print(f\"R-squared Score: {r2:.4f} (Model explains {r2 * 100:.2f}% of the variance)\")\n",
    "print(f\"MAPE: {mape:.2f}% (Predictions are off by an average of {mape:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 10))\n",
    "plt.plot(history.history['loss'], label = 'Training Loss (MSE)', color = 'blue')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss (MSE)', color = 'orange')\n",
    "plt.title('LSTM Learning Curve: Training Loss vs. Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (Mean Squared Error)')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.grid(True, linestyle = '--', alpha = 0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 10))\n",
    "plt.plot(y_predicted_converted_back, label = 'Actual vCores', color = 'blue', alpha = 0.6)\n",
    "plt.plot(y_actuals, label = 'Predicted vCores (5m ahead)', color='red', linestyle = '--', alpha = 0.8)\n",
    "plt.title('Test Data: Actual CPU Requests vs Predicted CPU Requests')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('vCores')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.grid(True, linestyle = '--', alpha = 0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Multi-Variable_LSTM_Model.keras')\n",
    "print(f\"Success: Model fully saved to Multi-Variable_LSTM_Model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_error = y_actuals * 0.10  # 10% margin of error\n",
    "absolute_errors = np.abs(y_actuals - y_predicted_converted_back)\n",
    "correct_predictions = np.sum(absolute_errors <= allowed_error)\n",
    "\n",
    "custom_accuracy = (correct_predictions / len(y_actuals)) * 100\n",
    "print(f\"Threshold Accuracy: {custom_accuracy:.2f}% of predictions were within a 10% margin of error.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOchetb3NWo6lVgdsrDNOTZ",
   "mount_file_id": "1Kr3nT9BrXQj_XOWERvySURI9uH7CdCQA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
