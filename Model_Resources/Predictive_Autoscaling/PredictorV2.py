import time
import datetime
import subprocess
import numpy as np
import joblib
import warnings  
import csv  
import os   
from tensorflow.keras.models import load_model

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏π‡∏î‡∏°‡∏≤‡∏Å (V2) ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Node
from DecisionEngineV2 import DecisionEngine
from node_manager import NodeManager

warnings.filterwarnings("ignore", category=UserWarning, module='sklearn')

# ==========================================
# 1. ‚öôÔ∏è CONFIGURATION (‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö)
# ==========================================
MODEL_PATH = 'best_single_var_model.keras'
SCALER_PATH = 'scaler.pkl'
WINDOW_SIZE = 30
LOG_FILE = 'autoscaler_log.csv' 

# ‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
# ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ï‡∏≠‡∏ô‡∏û‡∏£‡∏µ‡πÄ‡∏ã‡∏ô‡∏ï‡πå/‡πÄ‡∏ó‡∏™‡∏£‡∏∞‡∏ö‡∏ö = 1 | ‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏à‡∏£‡∏¥‡∏á = 60
LOOP_INTERVAL = 60

NODES = {
    'master': 'aj-aung-k8s-master',
    'worker1': 'aj-aung-k8s-worker1',
    'worker2': 'aj-aung-k8s-worker2'
}

AVAILABLE_WORKERS = ["10.35.29.109", "10.35.29.110"]

# ==========================================
# 2. üõ†Ô∏è HELPER FUNCTIONS
# ==========================================
def parse_k8s_value(value_str):
    if not value_str: return 0.0
    value_str = str(value_str).strip()
    try:
        if value_str.endswith('m'):
            return float(value_str.replace('m', '')) / 1000.0
        return float(value_str)
    except:
        return 0.0

def run_cmd(cmd):
    try:
        return subprocess.check_output(cmd, shell=True, stderr=subprocess.DEVNULL).decode('utf-8').strip()
    except:
        return ""

def fetch_realtime_data():
    total_cpu_req = 0.0
    worker_cpu_usage = 0.0
    worker_cpu_cap = 0.0
    active_workers = 0

    for key, node in NODES.items():
        status_out = run_cmd(f"kubectl get node {node} --no-headers | awk '{{print $2}}'")
        if "Ready" in status_out and "NotReady" not in status_out:
            # ‡∏î‡∏∂‡∏á Req ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            out_req = run_cmd(f"kubectl describe node {node} | grep -A 5 'Allocated resources' | tail -n 2")
            try:
                cpu_req = parse_k8s_value(out_req.splitlines()[0].split()[1])
                total_cpu_req += cpu_req
            except: pass

            # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Worker ‡∏°‡∏≤‡∏Ñ‡∏¥‡∏î % ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
            if key.startswith('worker'):
                active_workers += 1
                out_cap = run_cmd(f"kubectl get node {node} -o jsonpath='{{.status.capacity.cpu}}'")
                worker_cpu_cap += parse_k8s_value(out_cap)

                out_usage = run_cmd(f"kubectl top node {node} --no-headers | awk '{{print $2}}'")
                worker_cpu_usage += parse_k8s_value(out_usage)

    current_cpu_percent = 0.0
    if worker_cpu_cap > 0:
        current_cpu_percent = (worker_cpu_usage / worker_cpu_cap) * 100

    running_count = 0
    try:
        running_cmd = "kubectl get pods -n default --field-selector=status.phase=Running --no-headers | wc -l"
        running_count = int(run_cmd(running_cmd))
    except: pass

    pending_count = 0
    try:
        pending_cmd = "kubectl get pods -n default --field-selector=status.phase=Pending --no-headers | wc -l"
        pending_count = int(run_cmd(pending_cmd))
    except: pass

    return total_cpu_req, active_workers, pending_count, current_cpu_percent, running_count

# ==========================================
# üìù 2.5 ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ LOG (‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á)
# ==========================================
def init_logger():
    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, mode='w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                "Timestamp", 
                "Current_Workers", 
                "CPU_Usage_Percent", 
                "Running_Pods",
                "Pending_Pods", 
                "Current_Req_Cores", 
                "Predicted_Req_Cores", 
                "Action", 
                "Reason"
            ])
        print(f"üìÅ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Log ‡πÉ‡∏´‡∏°‡πà: {LOG_FILE}")

# ==========================================
# 3. üöÄ MAIN SYSTEM LOOP
# ==========================================
print("\n" + "="*50)
print(" üß† PREDICTIVE AUTOSCALER ENGINE (PROD. VERSION) ")
print("="*50)

print("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏•...")
try:
    model = load_model(MODEL_PATH, compile=False)
    scaler = joblib.load(SCALER_PATH)
    
    # üåü ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ DecisionEngineV2 ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î Reason ‡∏°‡∏≤‡πÉ‡∏´‡∏°‡πà
    decision_engine = DecisionEngine(cores_per_node=4.0, max_workers=2, min_workers=1)
    node_bot = NodeManager()
    
    init_logger() 
    
    print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á K8s Cluster ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏•‡πâ‡∏ß")
except Exception as e:
    print(f"‚ùå Error ‡∏ï‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {e}")
    exit()

history_buffer = []
print(f"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Monitor... (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡πÜ {LOOP_INTERVAL} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n")

# ==========================================
# üî• WARM START: ‡πÇ‡∏Ñ‡∏•‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≠‡∏Å AI ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ 30 ‡∏ô‡∏≤‡∏ó‡∏µ
# ==========================================
print("‚ö° [WARM START] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏Ñ‡∏•‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 30 ‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ...")
try:
    # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡∏°‡∏≤ 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (Single Var ‡πÄ‡∏£‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡πÅ‡∏Ñ‡πà cpu_req ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    initial_cpu_req, _, _, _, _ = fetch_realtime_data()
    
    # 2. ‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡∏Ñ‡πà‡∏≤ cpu_req ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏™‡πà‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡πá‡∏° 30 ‡∏ä‡πà‡∏≠‡∏á (‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏¥‡πà‡∏á‡∏°‡∏≤ 30 ‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏•‡πâ‡∏ß)
    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö [initial_cpu_req] ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Single-Var ‡πÉ‡∏ä‡πâ array 1 ‡∏°‡∏¥‡∏ï‡∏¥
    history_buffer = [[initial_cpu_req] for _ in range(WINDOW_SIZE)]
    print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≠‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! AI ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢!")
except Exception as e:
    print(f"‚ö†Ô∏è Warm Start ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e} (‡∏à‡∏∞‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏£‡∏≠‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥)")
# ==========================================

while True:
    try:
        current_dt = datetime.datetime.now()
        timestamp_full = current_dt.strftime("%Y-%m-%d %H:%M:%S")
        timestamp_short = current_dt.strftime("%H:%M:%S")
        
        # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        cpu_req, current_workers, pending_pods, cpu_usage_pct, running_pods = fetch_realtime_data()
        
        history_buffer.append([cpu_req])
        if len(history_buffer) > WINDOW_SIZE:
            history_buffer.pop(0)

        # 2. ‡∏£‡∏≠‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡∏Å‡πà‡∏≠‡∏ô AI ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        if len(history_buffer) < WINDOW_SIZE:
            print(f"[{timestamp_short}] ‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏∞‡∏™‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏´‡πâ AI... ({len(history_buffer)}/{WINDOW_SIZE}) | CPU Req: {cpu_req:.2f} Cores", end='\r')
            time.sleep(LOOP_INTERVAL) 
            continue

        # 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Dashboard
        print(f"\n[{timestamp_short}] " + "‚îÅ"*45)
        print(f"üìä [K8s Status] Worker Active: {current_workers} | CPU Usage: {cpu_usage_pct:.1f}% |Running Pods: {running_pods} |Pending Pods: {pending_pods}")

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ AI
        raw_array = np.array(history_buffer) 
        scaled_array = scaler.transform(raw_array)
        X_input = scaled_array.reshape(1, WINDOW_SIZE, 1)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
        pred_scaled = model.predict(X_input, verbose=0)
        predicted_cores = scaler.inverse_transform(pred_scaled)[0][0]
        
        print(f"üîÆ [AI Predict] CPU Request ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô {cpu_req:.2f} ‚û°Ô∏è  ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï {predicted_cores:.2f} Cores")

        # 4. ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ DecisionEngineV2 ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        action, reason = decision_engine.decide(
            predicted_cores=predicted_cores,
            current_workers=current_workers,
            pending_pods=pending_pods,
            current_cpu_usage=cpu_usage_pct,
            current_cpu_req=cpu_req
        )
        
        print(f"ü§ñ [Decision] : {action}")
        print(f"     [Reason] : {reason}") 
        
        # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á CSV
        try:
            with open(LOG_FILE, mode='a', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow([
                    timestamp_full,
                    current_workers,
                    round(cpu_usage_pct, 2),
                    running_pods,
                    pending_pods,
                    round(cpu_req, 2),
                    round(predicted_cores, 2),
                    action,
                    reason
                ])
        except Exception as log_err:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ ({log_err})")

        # 6. ‡∏™‡∏±‡πà‡∏á‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≥‡∏Å‡∏±‡∏ö K8s ‡∏à‡∏£‡∏¥‡∏á
        if action == "SCALE_OUT":
            if current_workers < len(AVAILABLE_WORKERS):
                target_ip = AVAILABLE_WORKERS[current_workers]
                print(f"üöÄ [ACTUATOR] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {target_ip} ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô...")
                node_bot.scale_up(target_ip)
            
        elif action == "SCALE_IN":
            if current_workers > 0:
                target_ip = AVAILABLE_WORKERS[current_workers - 1]
                print(f"üîª [ACTUATOR] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á {target_ip} ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£...")
                node_bot.scale_down(target_ip)

        print("‚îÅ"*58)
        
        # ‡∏û‡∏±‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏£‡∏≠‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ
        time.sleep(LOOP_INTERVAL)

    except KeyboardInterrupt:
        print("\n\nüõë ‡∏õ‡∏¥‡∏î‡∏£‡∏∞‡∏ö‡∏ö Predictive Autoscaler ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (Ctrl+C)")
        break
    except Exception as e:
        print(f"\n‚ùå Error ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏±‡∏ô‡∏•‡∏π‡∏õ: {e}")
        time.sleep(5)