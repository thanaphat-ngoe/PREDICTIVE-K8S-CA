import time
import datetime
import subprocess
import numpy as np
import joblib
import warnings  
from tensorflow.keras.models import load_model

warnings.filterwarnings("ignore", category=UserWarning, module='sklearn')

# ==========================================
# 1. âš™ï¸ CONFIGURATION
# ==========================================
MODEL_PATH = 'My_LSTM_Model.h5'    # Model à¹€à¸”à¸´à¸¡ (22 features)
SCALER_PATH = 'scaler.pkl'         # Scaler à¹€à¸”à¸´à¸¡
WINDOW_SIZE = 60                   # à¸•à¹‰à¸­à¸‡à¸•à¸£à¸‡à¸à¸±à¸šà¸•à¸­à¸™à¹€à¸—à¸£à¸™
MAX_CPU_CORES = 12.0               # à¹ƒà¸Šà¹‰à¸•à¸­à¸™à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¸à¸¥à¸±à¸š

NODES = {
    'master': 'aj-aung-k8s-master',
    'worker1': 'aj-aung-k8s-worker1',
    'worker2': 'aj-aung-k8s-worker2'
}

# ==========================================
# 2. ðŸ› ï¸ HELPER FUNCTIONS (à¹à¸›à¸¥à¸‡à¸«à¸™à¹ˆà¸§à¸¢à¹ƒà¸«à¹‰à¸•à¸£à¸‡ CSV)
# ==========================================
def parse_k8s_value(value_str):
    """
    à¹à¸›à¸¥à¸‡à¸„à¹ˆà¸²à¸ˆà¸²à¸ K8s à¹€à¸›à¹‡à¸™à¸«à¸™à¹ˆà¸§à¸¢à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸š Prometheus
    - CPU: Cores
    - Memory: Bytes 
    """
    if not value_str: return 0.0
    value_str = str(value_str).strip()
    
    try:
        # --- CPU (Cores) ---
        if value_str.endswith('m'):
            return float(value_str.replace('m', '')) / 1000.0
        
        # --- Memory (Bytes) ---
        if value_str.endswith('Ki'):
            return float(value_str.replace('Ki', '')) * 1024
        if value_str.endswith('Mi'):
            return float(value_str.replace('Mi', '')) * 1024 * 1024
        if value_str.endswith('Gi'):
            return float(value_str.replace('Gi', '')) * 1024 * 1024 * 1024
        if value_str.endswith('Ti'):
            return float(value_str.replace('Ti', '')) * 1024 * 1024 * 1024 * 1024
            
        return float(value_str)
    except:
        return 0.0

def run_cmd(cmd):
    try:
        return subprocess.check_output(cmd, shell=True).decode('utf-8').strip()
    except:
        return ""

def get_real_k8s_metrics_22():
    data = {}
    
    # 1. USAGE (kubectl top)
    output_top = run_cmd("kubectl top nodes --no-headers")
    for line in output_top.splitlines():
        parts = line.split()
        if len(parts) >= 4:
            node = parts[0]
            data[f"usage_{node}_cpu"] = parse_k8s_value(parts[1])
            data[f"usage_{node}_mem"] = parse_k8s_value(parts[3])

    # 2. CAP & REQ (kubectl get/describe)
    for key, node in NODES.items():
        # Cap
        out_cap = run_cmd(f"kubectl get node {node} -o jsonpath='{{.status.capacity.cpu}} {{.status.capacity.memory}}'").split()
        if len(out_cap) >= 2:
            data[f"cap_{node}_cpu"] = parse_k8s_value(out_cap[0])
            data[f"cap_{node}_mem"] = parse_k8s_value(out_cap[1])

        # Req
        out_req = run_cmd(f"kubectl describe node {node} | grep -A 5 'Allocated resources' | tail -n 2").splitlines()
        if len(out_req) >= 2:
            try:
                data[f"req_{node}_cpu"] = parse_k8s_value(out_req[0].split()[1])
                data[f"req_{node}_mem"] = parse_k8s_value(out_req[1].split()[1])
            except: pass

    # 3. PENDING (kubectl get pods)
    pending_count = 0.0
    try:
        pending_cmd = "kubectl get pods -A --field-selector=status.phase=Pending --no-headers | wc -l"
        pending_count = float(run_cmd(pending_cmd))
    except: pass

    # 4. ASSEMBLE FEATURES (22 à¸•à¸±à¸§)
    features = []
    def get(m, n, r): 
        return data.get(f"{m}_{NODES[n]}_{r}", 0.0)

    # --- à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸šà¹€à¸”à¸´à¸¡à¹€à¸›à¹Šà¸°à¹† (22 à¸Šà¹ˆà¸­à¸‡) ---
    
    # [0-2] Usage CPU (Master, W1, W2)
    features.extend([get('usage','master','cpu'), get('usage','worker1','cpu'), get('usage','worker2','cpu')])
    
    # [3-5] Usage Mem (Master, W1, W2)
    features.extend([get('usage','master','mem'), get('usage','worker1','mem'), get('usage','worker2','mem')])
    
    # [6] Req CPU Unknown
    features.append(0.0)
    
    # [7-9] Req CPU (Master, W1, W2)
    features.extend([get('req','master','cpu'), get('req','worker1','cpu'), get('req','worker2','cpu')])
    
    # [10] Req Mem Unknown (à¹€à¸•à¸´à¸¡ 0.0)
    features.append(0.0)
    
    # [11-13] Req Mem (Master, W1, W2)
    features.extend([get('req','master','mem'), get('req','worker1','mem'), get('req','worker2','mem')])
    
    # [14-16] Cap CPU (Master, W1, W2)
    features.extend([get('cap','master','cpu'), get('cap','worker1','cpu'), get('cap','worker2','cpu')])
    
    # [17-19] Cap Mem (Master, W1, W2)
    features.extend([get('cap','master','mem'), get('cap','worker1','mem'), get('cap','worker2','mem')])
    
    # [20] Pending Pods
    features.append(pending_count)

    # [21] Target: Total CPU Usag
    features.append(features[0] + features[1] + features[2])

    return features

# ==========================================
# 3. ðŸš€ MAIN SYSTEM
# ==========================================
print("â³ Loading Model & Scaler...")
try:
    model = load_model(MODEL_PATH, compile=False)
    scaler = joblib.load(SCALER_PATH)
    print("âœ… System Ready (Mode: 22 Features)!")
except Exception as e:
    print(f"âŒ Error: {e}")
    exit()

history = []
print(f"ðŸš€ Starting Monitor (Window={WINDOW_SIZE})...")

while True:
    try:
        # 1. Fetch Real Data
        real_features = get_real_k8s_metrics_22()
        
        # 2. Scale Data
        # scaler à¸„à¸²à¸”à¸«à¸§à¸±à¸‡ 22 features
        scaled_features = scaler.transform([real_features])[0]
        
        # 3. Update Buffer
        history.append(scaled_features)
        if len(history) > WINDOW_SIZE:
            history.pop(0)

        # 4. Process & Predict
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        
        if len(history) < WINDOW_SIZE:
            print(f"[{timestamp}] à¸ªà¸°à¸ªà¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥... ({len(history)}/{WINDOW_SIZE})", end='\r')
        else:
            # Prepare Input (1, 60, 22)
            input_np = np.array([history])
            
            # Predict
            pred_scaled = model.predict(input_np, verbose=0)[0][0]
            
            # Inverse Scale (à¹à¸›à¸¥à¸‡à¸à¸¥à¸±à¸šà¹€à¸›à¹‡à¸™ Cores)
            # à¸ªà¸£à¹‰à¸²à¸‡ Dummy array 22 à¸Šà¹ˆà¸­à¸‡ à¹€à¸žà¸·à¹ˆà¸­à¸«à¸¥à¸­à¸ scaler
            dummy = np.zeros((1, 22))
            dummy[0, -1] = pred_scaled # à¹ƒà¸ªà¹ˆà¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸—à¸³à¸™à¸²à¸¢à¹„à¸”à¹‰à¹ƒà¸™à¸Šà¹ˆà¸­à¸‡à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢ (Total CPU)
            pred_cores = scaler.inverse_transform(dummy)[0, -1]
            
            # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™à¹€à¸žà¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š
            current_cores_scaled = history[-1][-1]
            dummy[0, -1] = current_cores_scaled
            current_cores = scaler.inverse_transform(dummy)[0, -1]

            # Print Result
            print(f"                                                              ", end='\r')
            print(f"[{timestamp}] ðŸ“‰ à¸ˆà¸£à¸´à¸‡: {current_cores:.2f} | ðŸ”® à¸—à¸³à¸™à¸²à¸¢: {pred_cores:.2f} Cores")

        time.sleep(1)

    except KeyboardInterrupt:
        print("\nðŸ›‘ à¸«à¸¢à¸¸à¸”à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™")
        break
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        time.sleep(5)
